{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 5: Model Training\n",
        "\n",
        "## Objective\n",
        "Fine-tune BERT/RoBERTa for resume classification using our dataset with decision labels.\n",
        "\n",
        "## Goals\n",
        "1. Load the full resume screening dataset (10,000+ samples)\n",
        "2. Prepare training/validation/test splits\n",
        "3. Fine-tune BERT or RoBERTa for binary classification (Accepted/Rejected)\n",
        "4. Evaluate model performance (accuracy, F1, precision, recall)\n",
        "5. Save trained model weights for production\n",
        "\n",
        "## Dependencies\n",
        "- `transformers` - Hugging Face transformers library\n",
        "- `torch` - PyTorch for deep learning\n",
        "- `datasets` - Hugging Face datasets\n",
        "- `sklearn` - Metrics and data splitting\n",
        "- `pandas`, `numpy` - Data manipulation\n",
        "- `matplotlib`, `seaborn` - Visualization\n",
        "\n",
        "## Dataset\n",
        "Using **AzharAli05/Resume-Screening-Dataset** from Notebook 1 with decision labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "NVIDIA GeForce RTX 4060 Ti\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should be True\n",
        "print(torch.cuda.get_device_name(0))  # NVIDIA GeForce RTX 4060 Ti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From d:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "✓ All imports successful\n",
            "✓ PyTorch version: 2.8.0+cu129\n",
            "✓ Device: cuda\n",
            "✓ CUDA available: True\n",
            "✓ GPU: NVIDIA GeForce RTX 4060 Ti\n",
            "\n",
            "✓ Models directory: c:\\Users\\reza\\Desktop\\prj\\resume-analyzer\\notebooks\\..\\data\\models\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import load_dataset, load_from_disk, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define paths\n",
        "DATA_DIR = Path('../data')\n",
        "TRAINING_DIR = DATA_DIR / 'training'\n",
        "MODELS_DIR = DATA_DIR / 'models'\n",
        "\n",
        "# Create models directory\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"✓ All imports successful\")\n",
        "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
        "print(f\"✓ Device: {device}\")\n",
        "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"\\n✓ Models directory: {MODELS_DIR.absolute()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from: ..\\data\\training\\resume_screening_dataset\n",
            "✓ Dataset loaded successfully\n",
            "\n",
            "Dataset Information:\n",
            "  - Total samples: 10174\n",
            "  - Features: ['Role', 'Resume', 'Decision', 'Reason_for_decision', 'Job_Description']\n",
            "\n",
            "First example:\n",
            "{'Role': 'E-commerce Specialist', 'Resume': 'Here\\'s a professional resume for Jason Jones:\\n\\nJason Jones\\nE-commerce Specialist\\n\\nContact Information:\\n\\n* Email: [jasonjones@email.com](mailto:jasonjones@email.com)\\n* Phone: 555-123-4567\\n* LinkedIn: linkedin.com/in/jasonjones\\n\\nSummary:\\nResults-driven E-commerce Specialist with 5+ years of experience in inventory management, SEO, online advertising, and analytics. Proven track record of increasing online sales, improving website traffic, and optimizing inventory levels. Skilled in analyzing complex data sets, identifying trends, and making data-driven decisions. Passionate about staying up-to-date with the latest e-commerce trends and technologies.\\n\\nProfessional Experience:\\n\\nE-commerce Specialist, XYZ Corporation (2018-Present)\\n\\n* Managed inventory levels across multiple channels, resulting in a 25% reduction in stockouts and a 15% reduction in overstocking\\n* Developed and implemented SEO strategies that increased website traffic by 30% and improved search engine rankings by 20%\\n* Created and executed online advertising campaigns that generated a 50% increase in sales and a 20% increase in conversion rates\\n* Analyzed website analytics to identify trends, optimize user experience, and improve customer engagement\\n* Collaborated with cross-functional teams to launch new product lines, promotions, and marketing campaigns\\n\\nE-commerce Coordinator, ABC Retail (2015-2018)\\n\\n* Assisted in managing inventory levels, processing orders, and resolving customer inquiries\\n* Conducted keyword research and optimized product descriptions to improve search engine rankings\\n* Assisted in creating and executing online advertising campaigns, resulting in a 20% increase in sales\\n* Analyzed website analytics to identify trends and areas for improvement\\n\\nEducation:\\n\\n* Bachelor\\'s Degree in Business Administration, [University Name] (2015)\\n\\nSkills:\\n\\n* Inventory Management\\n* SEO for E-commerce\\n* Online Advertising (Google Ads, Facebook Ads)\\n* Analytics (Google Analytics, Excel)\\n* Data Analysis\\n* E-commerce Platforms (Shopify, WooCommerce)\\n* Customer Service\\n\\nAchievements:\\n\\n* Winner of the XYZ Corporation\\'s \"Innovator of the Year\" award for developing and implementing a data-driven approach to inventory management\\n* Featured speaker at the \"E-commerce Summit\" conference, presenting on \"Optimizing Inventory Levels for E-commerce Success\"\\n* Developed and implemented a social media strategy that increased followers by 500% and engagement by 200%\\n\\nCertifications:\\n\\n* Google Analytics Certification\\n* HubSpot Inbound Marketing Certification\\n* Shopify Plus Certification\\n\\nReferences:\\nAvailable upon request.', 'Decision': 'reject', 'Reason_for_decision': 'Lacked leadership skills for a senior position.', 'Job_Description': 'Be part of a passionate team at the forefront of machine learning as a E-commerce Specialist, delivering solutions that shape the future.'}\n"
          ]
        }
      ],
      "source": [
        "# Load the saved dataset from Notebook 1\n",
        "dataset_path = TRAINING_DIR / 'resume_screening_dataset'\n",
        "\n",
        "print(f\"Loading dataset from: {dataset_path}\")\n",
        "\n",
        "dataset = load_from_disk(str(dataset_path))\n",
        "\n",
        "print(f\"✓ Dataset loaded successfully\")\n",
        "print(f\"\\nDataset Information:\")\n",
        "print(f\"  - Total samples: {len(dataset)}\")\n",
        "print(f\"  - Features: {list(dataset.features.keys())}\")\n",
        "print(f\"\\nFirst example:\")\n",
        "print(dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Overview:\n",
            "  Shape: (10174, 5)\n",
            "\n",
            "Columns: ['Role', 'Resume', 'Decision', 'Reason_for_decision', 'Job_Description']\n",
            "\n",
            "Data types:\n",
            "Role                   object\n",
            "Resume                 object\n",
            "Decision               object\n",
            "Reason_for_decision    object\n",
            "Job_Description        object\n",
            "dtype: object\n",
            "\n",
            "First 3 rows:\n",
            "                         Role  \\\n",
            "0       E-commerce Specialist   \n",
            "1              Game Developer   \n",
            "2  Human Resources Specialist   \n",
            "\n",
            "                                              Resume Decision  \\\n",
            "0  Here's a professional resume for Jason Jones:\\...   reject   \n",
            "1  Here's a professional resume for Ann Marshall:...   select   \n",
            "2  Here's a professional resume for Patrick Mccla...   reject   \n",
            "\n",
            "                                 Reason_for_decision  \\\n",
            "0    Lacked leadership skills for a senior position.   \n",
            "1              Strong technical skills in AI and ML.   \n",
            "2  Insufficient system design expertise for senio...   \n",
            "\n",
            "                                     Job_Description  \n",
            "0  Be part of a passionate team at the forefront ...  \n",
            "1  Help us build the next-generation products as ...  \n",
            "2  We need a Human Resources Specialist to enhanc...  \n",
            "\n",
            "Searching for label/decision columns...\n",
            "  Found: Decision\n",
            "    Values: Decision\n",
            "reject    5114\n",
            "select    5060\n",
            "Name: count, dtype: int64\n",
            "  Found: Reason_for_decision\n",
            "    Values: Reason_for_decision\n",
            "Insufficient system design expertise for senior role.                                                                                                                             730\n",
            "Solid experience in machine learning and AI.                                                                                                                                      728\n",
            "Strong technical skills in AI and ML.                                                                                                                                             718\n",
            "No experience in back-end development.                                                                                                                                            717\n",
            "Needs improvement in machine learning algorithms.                                                                                                                                 707\n",
            "                                                                                                                                                                                 ... \n",
            "Limited experience of only 6 years and insufficient knowledge of Stakeholder management, User research led to this decision.                                                        1\n",
            "The candidate lacked sufficient expertise in key skills like Design systems, HTML, CSS, Usability testing, which are critical for the UI Designer role.                             1\n",
            "Limited experience of only 6 years and insufficient knowledge of SQL, Dashboards creation led to this decision.                                                                     1\n",
            "The candidate did not demonstrate strong competency in Statistical analysis, Big data tools, Deep learning frameworks, which are essential for a Data Scientist.                    1\n",
            "The candidate lacks sufficient expertise in crucial skills such as Cloud data tools, SQL optimization, Data storage solutions, which are essential for the Data Engineer role.      1\n",
            "Name: count, Length: 539, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Convert to pandas for exploration\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(\"Dataset Overview:\")\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Show first few rows to understand structure\n",
        "print(f\"\\nFirst 3 rows:\")\n",
        "print(df.head(3))\n",
        "\n",
        "# Check for any column with decision/label/class\n",
        "print(f\"\\nSearching for label/decision columns...\")\n",
        "for col in df.columns:\n",
        "    if any(keyword in col.lower() for keyword in ['decision', 'label', 'class', 'accept', 'reject']):\n",
        "        print(f\"  Found: {col}\")\n",
        "        print(f\"    Values: {df[col].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Comprehensive Data Cleaning\n",
        "\n",
        "Before training, we need to clean the data thoroughly to improve model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Dataset Statistics:\n",
            "================================================================================\n",
            "Total samples: 10174\n",
            "Columns: ['Role', 'Resume', 'Decision', 'Reason_for_decision', 'Job_Description']\n",
            "\n",
            "Missing values:\n",
            "Role                   0\n",
            "Resume                 0\n",
            "Decision               0\n",
            "Reason_for_decision    0\n",
            "Job_Description        0\n",
            "dtype: int64\n",
            "\n",
            "Decision distribution:\n",
            "Decision\n",
            "reject    5114\n",
            "select    5060\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Initial Dataset Statistics:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nDecision distribution:\")\n",
        "print(df['Decision'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Remove Duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate Analysis:\n",
            "  Total duplicates found: 0\n",
            "  ✓ No duplicates found\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicate resumes\n",
        "initial_count = len(df)\n",
        "duplicates = df.duplicated(subset=['Resume']).sum()\n",
        "\n",
        "print(f\"Duplicate Analysis:\")\n",
        "print(f\"  Total duplicates found: {duplicates}\")\n",
        "\n",
        "if duplicates > 0:\n",
        "    df = df.drop_duplicates(subset=['Resume'], keep='first')\n",
        "    print(f\"  Removed {initial_count - len(df)} duplicate resumes\")\n",
        "    print(f\"  New dataset size: {len(df)}\")\n",
        "else:\n",
        "    print(f\"  ✓ No duplicates found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Remove Synthetic Template Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing synthetic template text...\n",
            "✓ Template text removed\n",
            "  Average resume length before: 2884 chars\n",
            "  Average resume length after: 2846 chars\n",
            "  Reduction: 38 chars (1.3%)\n"
          ]
        }
      ],
      "source": [
        "# Remove AI-generated template prefixes\n",
        "print(\"Removing synthetic template text...\")\n",
        "\n",
        "# Patterns to remove\n",
        "template_patterns = [\n",
        "    r\"Here's a professional resume for .*?:\",\n",
        "    r\"Here is a professional resume for .*?:\",\n",
        "    r\"Professional resume for .*?:\",\n",
        "    r\"Resume for .*?:\",\n",
        "]\n",
        "\n",
        "df['Resume_cleaned'] = df['Resume'].copy()\n",
        "\n",
        "for pattern in template_patterns:\n",
        "    df['Resume_cleaned'] = df['Resume_cleaned'].str.replace(pattern, \"\", regex=True, case=False)\n",
        "\n",
        "# Remove extra whitespace\n",
        "df['Resume_cleaned'] = df['Resume_cleaned'].str.strip()\n",
        "\n",
        "# Check improvement\n",
        "avg_before = df['Resume'].str.len().mean()\n",
        "avg_after = df['Resume_cleaned'].str.len().mean()\n",
        "\n",
        "print(f\"✓ Template text removed\")\n",
        "print(f\"  Average resume length before: {avg_before:.0f} chars\")\n",
        "print(f\"  Average resume length after: {avg_after:.0f} chars\")\n",
        "print(f\"  Reduction: {(avg_before - avg_after):.0f} chars ({(avg_before-avg_after)/avg_before*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Combine Resume with Job Description (CRITICAL!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combining Resume with Job Description...\n",
            "✓ Combined resume + job description\n",
            "  Average combined text length: 3251 chars\n",
            "  Max length: 8,638 chars\n",
            "  Min length: 137 chars\n"
          ]
        }
      ],
      "source": [
        "# CRITICAL: The decision is based on resume + job description match!\n",
        "# We need to give the model BOTH to make accurate predictions\n",
        "\n",
        "print(\"Combining Resume with Job Description...\")\n",
        "\n",
        "df['full_text'] = (\n",
        "    \"RESUME: \" + df['Resume_cleaned'] + \n",
        "    \" [SEP] JOB DESCRIPTION: \" + df['Job_Description']\n",
        ")\n",
        "\n",
        "print(f\"✓ Combined resume + job description\")\n",
        "print(f\"  Average combined text length: {df['full_text'].str.len().mean():.0f} chars\")\n",
        "print(f\"  Max length: {df['full_text'].str.len().max():,} chars\")\n",
        "print(f\"  Min length: {df['full_text'].str.len().min():,} chars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Filter Low-Quality Samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 2 resumes shorter than 100 chars\n",
            "Removed 0 job descriptions shorter than 50 chars\n",
            "Removed 0 samples with missing data\n",
            "\n",
            "✓ Filtered low-quality samples\n",
            "  Remaining samples: 10172\n"
          ]
        }
      ],
      "source": [
        "# Filter criteria\n",
        "initial_count = len(df)\n",
        "\n",
        "# 1. Remove very short resumes (likely incomplete)\n",
        "min_resume_length = 100\n",
        "df = df[df['Resume_cleaned'].str.len() >= min_resume_length]\n",
        "print(f\"Removed {initial_count - len(df)} resumes shorter than {min_resume_length} chars\")\n",
        "\n",
        "# 2. Remove very short job descriptions\n",
        "initial_count = len(df)\n",
        "min_job_desc_length = 50\n",
        "df = df[df['Job_Description'].str.len() >= min_job_desc_length]\n",
        "print(f\"Removed {initial_count - len(df)} job descriptions shorter than {min_job_desc_length} chars\")\n",
        "\n",
        "# 3. Remove empty or null values\n",
        "initial_count = len(df)\n",
        "df = df.dropna(subset=['Resume_cleaned', 'Job_Description', 'Decision'])\n",
        "print(f\"Removed {initial_count - len(df)} samples with missing data\")\n",
        "\n",
        "print(f\"\\n✓ Filtered low-quality samples\")\n",
        "print(f\"  Remaining samples: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Handle Text Length Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Length Distribution:\n",
            "  Q1 (25th percentile): 2839\n",
            "  Median (50th): 3053\n",
            "  Q3 (75th percentile): 3314\n",
            "  IQR: 475\n",
            "  Lower bound: 2126\n",
            "  Upper bound: 4026\n",
            "\n",
            "  Outliers detected: 1118 (11.0%)\n",
            "\n",
            "✓ Removed 919 extreme outliers\n",
            "  Remaining samples: 9253\n"
          ]
        }
      ],
      "source": [
        "# Analyze text length distribution\n",
        "df['text_length'] = df['full_text'].str.len()\n",
        "\n",
        "# Calculate quartiles and IQR for outlier detection\n",
        "Q1 = df['text_length'].quantile(0.25)\n",
        "Q3 = df['text_length'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outlier bounds (1.5 * IQR method)\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(\"Text Length Distribution:\")\n",
        "print(f\"  Q1 (25th percentile): {Q1:.0f}\")\n",
        "print(f\"  Median (50th): {df['text_length'].median():.0f}\")\n",
        "print(f\"  Q3 (75th percentile): {Q3:.0f}\")\n",
        "print(f\"  IQR: {IQR:.0f}\")\n",
        "print(f\"  Lower bound: {lower_bound:.0f}\")\n",
        "print(f\"  Upper bound: {upper_bound:.0f}\")\n",
        "\n",
        "# Count outliers\n",
        "outliers = ((df['text_length'] < lower_bound) | (df['text_length'] > upper_bound)).sum()\n",
        "print(f\"\\n  Outliers detected: {outliers} ({outliers/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Remove extreme outliers only (beyond 3*IQR)\n",
        "extreme_lower = Q1 - 3 * IQR\n",
        "extreme_upper = Q3 + 3 * IQR\n",
        "\n",
        "initial_count = len(df)\n",
        "df = df[(df['text_length'] >= extreme_lower) & (df['text_length'] <= extreme_upper)]\n",
        "\n",
        "print(f\"\\n✓ Removed {initial_count - len(df)} extreme outliers\")\n",
        "print(f\"  Remaining samples: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Analyze Decision Patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Pattern Analysis:\n",
            "================================================================================\n",
            "\n",
            "Text length by decision:\n",
            "           count         mean         std     min     25%     50%     75%  \\\n",
            "Decision                                                                    \n",
            "reject    4659.0  3075.254990  391.083889  1427.0  2843.5  3054.0  3285.5   \n",
            "select    4594.0  3023.847845  331.017730  1452.0  2834.0  3016.5  3222.0   \n",
            "\n",
            "             max  \n",
            "Decision          \n",
            "reject    4693.0  \n",
            "select    4665.0  \n",
            "\n",
            "Word count by decision:\n",
            "                mean    50%    25%    75%\n",
            "Decision                                 \n",
            "reject    391.447736  386.0  356.0  418.0\n",
            "select    383.185242  381.0  355.0  411.0\n",
            "\n",
            "Acceptance rate by top 10 roles:\n",
            "  Data Scientist                : 52.5% selected (444 samples)\n",
            "  Software Engineer             : 50.3% selected (368 samples)\n",
            "  Data Engineer                 : 44.1% selected (354 samples)\n",
            "  Product Manager               : 49.4% selected (346 samples)\n",
            "  Data Analyst                  : 51.7% selected (319 samples)\n",
            "  data engineer                 : 48.2% selected (307 samples)\n",
            "  software engineer             : 45.4% selected (306 samples)\n",
            "  product manager               : 48.5% selected (303 samples)\n",
            "  data scientist                : 46.7% selected (287 samples)\n",
            "  UI Engineer                   : 49.6% selected (272 samples)\n"
          ]
        }
      ],
      "source": [
        "# Analyze if there are patterns in the data\n",
        "print(\"Decision Pattern Analysis:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Group by decision and analyze text lengths\n",
        "print(\"\\nText length by decision:\")\n",
        "decision_stats = df.groupby('Decision')['text_length'].describe()\n",
        "print(decision_stats)\n",
        "\n",
        "# Word count analysis\n",
        "df['word_count'] = df['Resume_cleaned'].str.split().str.len()\n",
        "print(\"\\nWord count by decision:\")\n",
        "print(df.groupby('Decision')['word_count'].describe()[['mean', '50%', '25%', '75%']])\n",
        "\n",
        "# Check if certain roles have different acceptance rates\n",
        "print(\"\\nAcceptance rate by top 10 roles:\")\n",
        "top_roles = df['Role'].value_counts().head(10).index\n",
        "for role in top_roles:\n",
        "    role_df = df[df['Role'] == role]\n",
        "    select_rate = (role_df['Decision'] == 'select').sum() / len(role_df) * 100\n",
        "    print(f\"  {role:30s}: {select_rate:.1f}% selected ({len(role_df)} samples)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Balance Classes (If Needed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Balance Analysis:\n",
            "  Select: 4594 (49.6%)\n",
            "  Reject: 4659 (50.4%)\n",
            "  Imbalance ratio: 1.01:1\n",
            "\n",
            "  ✓ Classes are well balanced\n"
          ]
        }
      ],
      "source": [
        "# Check class balance\n",
        "select_count = (df['Decision'] == 'select').sum()\n",
        "reject_count = (df['Decision'] == 'reject').sum()\n",
        "imbalance_ratio = max(select_count, reject_count) / min(select_count, reject_count)\n",
        "\n",
        "print(f\"Class Balance Analysis:\")\n",
        "print(f\"  Select: {select_count} ({select_count/len(df)*100:.1f}%)\")\n",
        "print(f\"  Reject: {reject_count} ({reject_count/len(df)*100:.1f}%)\")\n",
        "print(f\"  Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "# If imbalance > 1.2:1, consider balancing\n",
        "if imbalance_ratio > 1.2:\n",
        "    print(f\"\\n  ⚠ Classes are imbalanced (>{1.2}:1)\")\n",
        "    print(f\"  Consider: undersample majority or oversample minority\")\n",
        "    \n",
        "    # Optional: Balance by undersampling majority class\n",
        "    # min_class_size = min(select_count, reject_count)\n",
        "    # df_select = df[df['Decision'] == 'select'].sample(n=min_class_size, random_state=42)\n",
        "    # df_reject = df[df['Decision'] == 'reject'].sample(n=min_class_size, random_state=42)\n",
        "    # df = pd.concat([df_select, df_reject]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "else:\n",
        "    print(f\"\\n  ✓ Classes are well balanced\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Text Normalization and Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying advanced text cleaning...\n",
            "✓ Text cleaning complete\n",
            "  Average final text length: 2959 chars\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Advanced text cleaning for better model performance.\"\"\"\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # Remove special markdown/HTML artifacts\n",
        "    text = re.sub(r'[*_]{2,}', '', text)  # Remove **bold** or __underline__\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
        "    \n",
        "    # Normalize newlines\n",
        "    text = text.replace('\\\\n', '\\n')\n",
        "    \n",
        "    # Remove email placeholders\n",
        "    text = re.sub(r'\\[.*?@.*?\\]\\(mailto:.*?\\)', '', text)\n",
        "    \n",
        "    # Remove excessive punctuation\n",
        "    text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "# Apply cleaning\n",
        "print(\"Applying advanced text cleaning...\")\n",
        "df['Resume_cleaned'] = df['Resume_cleaned'].apply(clean_text)\n",
        "df['Job_Description'] = df['Job_Description'].apply(clean_text)\n",
        "\n",
        "# Recreate combined text\n",
        "df['full_text'] = (\n",
        "    \"RESUME: \" + df['Resume_cleaned'] + \n",
        "    \" [SEP] JOB: \" + df['Job_Description']\n",
        ")\n",
        "\n",
        "print(\"✓ Text cleaning complete\")\n",
        "print(f\"  Average final text length: {df['full_text'].str.len().mean():.0f} chars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Verify Data Quality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Data Quality Report:\n",
            "================================================================================\n",
            "  Empty resumes: 0\n",
            "  Empty job descriptions: 0\n",
            "\n",
            "  Missing values:\n",
            "    Resume: 0\n",
            "    Job Description: 0\n",
            "    Decision: 0\n",
            "\n",
            "  Text length statistics:\n",
            "    Min: 1350 chars\n",
            "    Max: 4597 chars\n",
            "    Mean: 2959 chars\n",
            "    Median: 2947 chars\n",
            "\n",
            "  Label distribution:\n",
            "    reject: 4659\n",
            "    select: 4594\n",
            "\n",
            "✓ Data quality verified\n",
            "  Final clean dataset: 9253 samples\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Final data quality checks\n",
        "print(\"Final Data Quality Report:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check for empty text\n",
        "empty_resumes = (df['Resume_cleaned'].str.len() == 0).sum()\n",
        "empty_jobs = (df['Job_Description'].str.len() == 0).sum()\n",
        "print(f\"  Empty resumes: {empty_resumes}\")\n",
        "print(f\"  Empty job descriptions: {empty_jobs}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\n  Missing values:\")\n",
        "print(f\"    Resume: {df['Resume_cleaned'].isna().sum()}\")\n",
        "print(f\"    Job Description: {df['Job_Description'].isna().sum()}\")\n",
        "print(f\"    Decision: {df['Decision'].isna().sum()}\")\n",
        "\n",
        "# Check text length stats\n",
        "print(f\"\\n  Text length statistics:\")\n",
        "print(f\"    Min: {df['full_text'].str.len().min()} chars\")\n",
        "print(f\"    Max: {df['full_text'].str.len().max()} chars\")\n",
        "print(f\"    Mean: {df['full_text'].str.len().mean():.0f} chars\")\n",
        "print(f\"    Median: {df['full_text'].str.len().median():.0f} chars\")\n",
        "\n",
        "# Verify labels\n",
        "print(f\"\\n  Label distribution:\")\n",
        "print(f\"    reject: {(df['Decision'] == 'reject').sum()}\")\n",
        "print(f\"    select: {(df['Decision'] == 'select').sum()}\")\n",
        "\n",
        "print(f\"\\n✓ Data quality verified\")\n",
        "print(f\"  Final clean dataset: {len(df)} samples\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Before/After Cleaning Example:\n",
            "================================================================================\n",
            "BEFORE:\n",
            "Here's a professional resume for Jason Jones:\n",
            "\n",
            "Jason Jones\n",
            "E-commerce Specialist\n",
            "\n",
            "Contact Information:\n",
            "\n",
            "* Email: [jasonjones@email.com](mailto:jasonjones@email.com)\n",
            "* Phone: 555-123-4567\n",
            "* LinkedIn: linkedin.com/in/jasonjones\n",
            "\n",
            "Summary:\n",
            "Results-driven E-commerce Specialist with 5+ years of experience\n",
            "\n",
            "AFTER:\n",
            "Jason Jones E-commerce Specialist Contact Information: * Email:  * Phone: 555-123-4567 * LinkedIn: linkedin.com/in/jasonjones Summary: Results-driven E-commerce Specialist with 5+ years of experience in inventory management, SEO, online advertising, and analytics. Proven track record of increasing o\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Show before/after cleaning example\n",
        "print(\"\\nBefore/After Cleaning Example:\")\n",
        "print(\"=\"*80)\n",
        "print(\"BEFORE:\")\n",
        "print(df.iloc[0]['Resume'][:300])\n",
        "print(\"\\nAFTER:\")\n",
        "print(df.iloc[0]['Resume_cleaned'][:300])\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Labels and Prepare for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Encoding:\n",
            "  'reject' -> 0 (Negative class)\n",
            "  'select' -> 1 (Positive class)\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "0    4659\n",
            "1    4594\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class balance:\n",
            "  Reject: 4659 (50.4%)\n",
            "  Select: 4594 (49.6%)\n",
            "\n",
            "✓ All 9253 samples have valid labels\n"
          ]
        }
      ],
      "source": [
        "# Create binary labels using cleaned data\n",
        "label_map = {\n",
        "    'reject': 0,\n",
        "    'select': 1\n",
        "}\n",
        "\n",
        "df['label'] = df['Decision'].map(label_map)\n",
        "\n",
        "print(\"Label Encoding:\")\n",
        "print(\"  'reject' -> 0 (Negative class)\")\n",
        "print(\"  'select' -> 1 (Positive class)\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts().sort_index())\n",
        "print(f\"\\nClass balance:\")\n",
        "print(f\"  Reject: {(df['label']==0).sum()} ({(df['label']==0).sum()/len(df)*100:.1f}%)\")\n",
        "print(f\"  Select: {(df['label']==1).sum()} ({(df['label']==1).sum()/len(df)*100:.1f}%)\")\n",
        "print(f\"\\n✓ All {len(df)} samples have valid labels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Split:\n",
            "  Training: 7402 samples (80.0%)\n",
            "  Validation: 925 samples (10.0%)\n",
            "  Test: 926 samples (10.0%)\n",
            "\n",
            "Class distribution in splits:\n",
            "  Train - Reject: 3727, Select: 3675\n",
            "  Val   - Reject: 466, Select: 459\n",
            "  Test  - Reject: 466, Select: 460\n"
          ]
        }
      ],
      "source": [
        "# Split dataset: 80% train, 10% validation, 10% test\n",
        "train_df, temp_df = train_test_split(\n",
        "    df, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df, \n",
        "    test_size=0.5, \n",
        "    random_state=42, \n",
        "    stratify=temp_df['label']\n",
        ")\n",
        "\n",
        "print(\"Dataset Split:\")\n",
        "print(f\"  Training: {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Validation: {len(val_df)} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Test: {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nClass distribution in splits:\")\n",
        "print(f\"  Train - Reject: {(train_df['label']==0).sum()}, Select: {(train_df['label']==1).sum()}\")\n",
        "print(f\"  Val   - Reject: {(val_df['label']==0).sum()}, Select: {(val_df['label']==1).sum()}\")\n",
        "print(f\"  Test  - Reject: {(test_df['label']==0).sum()}, Select: {(test_df['label']==1).sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Datasets converted to Hugging Face format\n",
            "  Train: 7402 samples\n",
            "  Validation: 925 samples\n",
            "  Test: 926 samples\n",
            "\n",
            "  Using 'full_text' column (resume + job description combined)\n"
          ]
        }
      ],
      "source": [
        "# Convert to Hugging Face Dataset format - USE CLEANED TEXT!\n",
        "train_dataset = Dataset.from_pandas(train_df[['full_text', 'label']].rename(columns={'full_text': 'text'}).reset_index(drop=True))\n",
        "val_dataset = Dataset.from_pandas(val_df[['full_text', 'label']].rename(columns={'full_text': 'text'}).reset_index(drop=True))\n",
        "test_dataset = Dataset.from_pandas(test_df[['full_text', 'label']].rename(columns={'full_text': 'text'}).reset_index(drop=True))\n",
        "\n",
        "print(\"\\n✓ Datasets converted to Hugging Face format\")\n",
        "print(f\"  Train: {len(train_dataset)} samples\")\n",
        "print(f\"  Validation: {len(val_dataset)} samples\")\n",
        "print(f\"  Test: {len(test_dataset)} samples\")\n",
        "print(f\"\\n  Using 'full_text' column (resume + job description combined)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Pre-trained Model and Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: distilbert-base-uncased\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model loaded successfully\n",
            "✓ Model size: 66,955,010 parameters\n",
            "✓ Tokenizer vocab size: 30,522\n"
          ]
        }
      ],
      "source": [
        "# Model selection: Using DistilBERT\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "print(f\"Loading model: {model_name}\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load model for binary classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    id2label={0: \"Rejected\", 1: \"Selected\"},\n",
        "    label2id={\"Rejected\": 0, \"Selected\": 1}\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"✓ Model loaded successfully\")\n",
        "print(f\"✓ Model size: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "print(f\"✓ Tokenizer vocab size: {tokenizer.vocab_size:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Tokenize Cleaned Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing cleaned datasets...\n",
            "  Using combined resume + job description text\n",
            "  This may take a few minutes...\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "389f2df7715b45509fed5b7142491230",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7402 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26753e138e724e63a6309d3fa1f94d27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/925 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfaea573bf9c4b0ab04abd61f070cc25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/926 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Tokenization complete\n",
            "  Train samples: 7402\n",
            "  Val samples: 925\n",
            "  Test samples: 926\n"
          ]
        }
      ],
      "source": [
        "# Tokenization function - NOW USES 'text' COLUMN (cleaned data)\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize combined resume + job description text.\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['text'],  # Now using combined text\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=False\n",
        "    )\n",
        "\n",
        "print(\"Tokenizing cleaned datasets...\")\n",
        "print(\"  Using combined resume + job description text\")\n",
        "print(\"  This may take a few minutes...\\n\")\n",
        "\n",
        "# Tokenize all splits with cleaned data\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "\n",
        "print(\"✓ Tokenization complete\")\n",
        "print(f\"  Train samples: {len(tokenized_train)}\")\n",
        "print(f\"  Val samples: {len(tokenized_val)}\")\n",
        "print(f\"  Test samples: {len(tokenized_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Configuration (Updated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated Training Configuration:\n",
            "  Epochs: 4\n",
            "  Batch size (train): 16\n",
            "  Batch size (eval): 32\n",
            "  Learning rate: 3e-05\n",
            "  Warmup steps: 500\n",
            "  Best model metric: f1\n",
            "  FP16: True\n"
          ]
        }
      ],
      "source": [
        "# Training arguments - OPTIMIZED\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(MODELS_DIR / 'resume_classifier_v2'),\n",
        "    num_train_epochs=4,  # Increased from 3 to 4\n",
        "    per_device_train_batch_size=16,  # Increased from 8 (your GPU can handle it)\n",
        "    per_device_eval_batch_size=32,  # Increased from 16\n",
        "    learning_rate=3e-5,  # Slightly higher for better learning\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=500,  # Gradual learning rate warmup\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",  # Changed from accuracy to F1\n",
        "    logging_dir=str(MODELS_DIR / 'logs_v2'),\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        "    seed=42,\n",
        "    fp16=True,  # Your RTX 4060 Ti supports this\n",
        ")\n",
        "\n",
        "print(\"Updated Training Configuration:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size (train): {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Batch size (eval): {training_args.per_device_eval_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  Warmup steps: {training_args.warmup_steps}\")\n",
        "print(f\"  Best model metric: {training_args.metric_for_best_model}\")\n",
        "print(f\"  FP16: {training_args.fp16}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Metrics and data collator initialized\n"
          ]
        }
      ],
      "source": [
        "# Metrics computation\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy, precision, recall, and F1 score.\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    \n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary'\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "print(\"✓ Metrics and data collator initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train Model with Cleaned Data\n",
        "\n",
        "**Expected Improvements:**\n",
        "- Better accuracy (targeting 75-85%)\n",
        "- Higher confidence scores\n",
        "- Better decision patterns (resume+job fit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Trainer initialized with cleaned data\n",
            "\n",
            "READY TO TRAIN!\n",
            "================================================================================\n",
            "Changes from previous training:\n",
            "  ✓ Removed synthetic template text\n",
            "  ✓ Combined resume + job description\n",
            "  ✓ Filtered low-quality samples\n",
            "  ✓ Removed outliers\n",
            "  ✓ Increased batch size (16 vs 8)\n",
            "  ✓ Added warmup steps\n",
            "  ✓ Optimized for F1 score\n",
            "================================================================================\n",
            "\n",
            "Expected time: 15-25 minutes on RTX 4060 Ti\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\reza\\AppData\\Local\\Temp\\ipykernel_10084\\2471776677.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Initialize Trainer with cleaned data\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"✓ Trainer initialized with cleaned data\")\n",
        "print(\"\\nREADY TO TRAIN!\")\n",
        "print(\"=\"*80)\n",
        "print(\"Changes from previous training:\")\n",
        "print(\"  ✓ Removed synthetic template text\")\n",
        "print(\"  ✓ Combined resume + job description\")\n",
        "print(\"  ✓ Filtered low-quality samples\")\n",
        "print(\"  ✓ Removed outliers\")\n",
        "print(\"  ✓ Increased batch size (16 vs 8)\")\n",
        "print(\"  ✓ Added warmup steps\")\n",
        "print(\"  ✓ Optimized for F1 score\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nExpected time: 15-25 minutes on RTX 4060 Ti\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STARTING TRAINING (V2 - WITH CLEANED DATA)\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1852' max='1852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1852/1852 04:16, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.600764</td>\n",
              "      <td>0.557838</td>\n",
              "      <td>0.528802</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.691786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.624600</td>\n",
              "      <td>0.610596</td>\n",
              "      <td>0.578378</td>\n",
              "      <td>0.785124</td>\n",
              "      <td>0.206972</td>\n",
              "      <td>0.327586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.606300</td>\n",
              "      <td>0.596601</td>\n",
              "      <td>0.571892</td>\n",
              "      <td>0.560928</td>\n",
              "      <td>0.631808</td>\n",
              "      <td>0.594262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.592700</td>\n",
              "      <td>0.610930</td>\n",
              "      <td>0.568649</td>\n",
              "      <td>0.548860</td>\n",
              "      <td>0.734205</td>\n",
              "      <td>0.628145</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETED!\n",
            "================================================================================\n",
            "\n",
            "Training metrics:\n",
            "  Training loss: 0.6206\n",
            "  Training runtime: 257.05 seconds\n",
            "  Training samples/second: 115.18\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "print(\"=\"*80)\n",
        "print(\"STARTING TRAINING (V2 - WITH CLEANED DATA)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTraining metrics:\")\n",
        "print(f\"  Training loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"  Training runtime: {train_result.metrics['train_runtime']:.2f} seconds\")\n",
        "print(f\"  Training samples/second: {train_result.metrics['train_samples_per_second']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Prepare Data for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Encoding:\n",
            "  'reject' -> 0 (Negative class)\n",
            "  'select' -> 1 (Positive class)\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "0    4659\n",
            "1    4594\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class balance:\n",
            "  Reject: 4659 (50.4%)\n",
            "  Select: 4594 (49.6%)\n",
            "\n",
            "✓ All 9253 samples have valid labels\n"
          ]
        }
      ],
      "source": [
        "# Create binary labels - FIXED VERSION\n",
        "# Dataset uses 'reject' and 'select' (not 'Rejected'/'Accepted')\n",
        "label_map = {\n",
        "    'reject': 0,\n",
        "    'select': 1\n",
        "}\n",
        "\n",
        "df['label'] = df['Decision'].map(label_map)\n",
        "\n",
        "print(\"Label Encoding:\")\n",
        "print(\"  'reject' -> 0 (Negative class)\")\n",
        "print(\"  'select' -> 1 (Positive class)\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts().sort_index())\n",
        "print(f\"\\nClass balance:\")\n",
        "print(f\"  Reject: {(df['label']==0).sum()} ({(df['label']==0).sum()/len(df)*100:.1f}%)\")\n",
        "print(f\"  Select: {(df['label']==1).sum()} ({(df['label']==1).sum()/len(df)*100:.1f}%)\")\n",
        "print(f\"\\n✓ All {len(df)} samples have valid labels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Split:\n",
            "  Training: 7402 samples (80.0%)\n",
            "  Validation: 925 samples (10.0%)\n",
            "  Test: 926 samples (10.0%)\n",
            "\n",
            "Class distribution in splits:\n",
            "  Train - Rejected: 3727, Accepted: 3675\n",
            "  Val   - Rejected: 466, Accepted: 459\n",
            "  Test  - Rejected: 466, Accepted: 460\n"
          ]
        }
      ],
      "source": [
        "# Split dataset: 80% train, 10% validation, 10% test\n",
        "# First split: 80% train, 20% temp\n",
        "train_df, temp_df = train_test_split(\n",
        "    df, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "# Second split: 50% of temp for validation, 50% for test\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df, \n",
        "    test_size=0.5, \n",
        "    random_state=42, \n",
        "    stratify=temp_df['label']\n",
        ")\n",
        "\n",
        "print(\"Dataset Split:\")\n",
        "print(f\"  Training: {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Validation: {len(val_df)} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Test: {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nClass distribution in splits:\")\n",
        "print(f\"  Train - Rejected: {(train_df['label']==0).sum()}, Accepted: {(train_df['label']==1).sum()}\")\n",
        "print(f\"  Val   - Rejected: {(val_df['label']==0).sum()}, Accepted: {(val_df['label']==1).sum()}\")\n",
        "print(f\"  Test  - Rejected: {(test_df['label']==0).sum()}, Accepted: {(test_df['label']==1).sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Datasets converted to Hugging Face format\n",
            "  Train: 7402 samples\n",
            "  Validation: 925 samples\n",
            "  Test: 926 samples\n"
          ]
        }
      ],
      "source": [
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df[['Resume', 'label']].reset_index(drop=True))\n",
        "val_dataset = Dataset.from_pandas(val_df[['Resume', 'label']].reset_index(drop=True))\n",
        "test_dataset = Dataset.from_pandas(test_df[['Resume', 'label']].reset_index(drop=True))\n",
        "\n",
        "print(\"\\n✓ Datasets converted to Hugging Face format\")\n",
        "print(f\"  Train: {len(train_dataset)} samples\")\n",
        "print(f\"  Validation: {len(val_dataset)} samples\")\n",
        "print(f\"  Test: {len(test_dataset)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Pre-trained Model and Tokenizer\n",
        "\n",
        "We'll use DistilBERT - a smaller, faster version of BERT that's perfect for this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model loaded successfully\n",
            "✓ Model size: 66,955,010 parameters\n",
            "✓ Tokenizer vocab size: 30,522\n"
          ]
        }
      ],
      "source": [
        "# Model selection: Using DistilBERT (smaller and faster than BERT)\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load model for binary classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,  # Binary classification\n",
        "    id2label={0: \"Rejected\", 1: \"Accepted\"},\n",
        "    label2id={\"Rejected\": 0, \"Accepted\": 1}\n",
        ")\n",
        "\n",
        "# Move model to device (GPU if available)\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"✓ Model loaded successfully\")\n",
        "print(f\"✓ Model size: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "print(f\"✓ Tokenizer vocab size: {tokenizer.vocab_size:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Tokenize Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing datasets...\n",
            "  This may take a few minutes...\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba4eb2cc8dc44e7c9e6e4f705273a315",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7402 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b305600de16d4360b070b45d23879d92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/925 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a49cf862283249df94b38301f41de527",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/926 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Tokenization complete\n",
            "\n",
            "Tokenized dataset features: {'label': Value('int64'), 'input_ids': List(Value('int32')), 'attention_mask': List(Value('int8'))}\n"
          ]
        }
      ],
      "source": [
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize resume text with truncation and padding.\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['Resume'],\n",
        "        truncation=True,\n",
        "        max_length=512,  # BERT max sequence length\n",
        "        padding=False  # We'll pad dynamically during training\n",
        "    )\n",
        "\n",
        "print(\"Tokenizing datasets...\")\n",
        "print(\"  This may take a few minutes...\\n\")\n",
        "\n",
        "# Tokenize all splits\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=['Resume'])\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True, remove_columns=['Resume'])\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True, remove_columns=['Resume'])\n",
        "\n",
        "print(\"✓ Tokenization complete\")\n",
        "print(f\"\\nTokenized dataset features: {tokenized_train.features}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization Example:\n",
            "  Input IDs length: 512\n",
            "  First 20 tokens: [101, 2182, 1005, 1055, 1037, 2658, 13746, 2005, 4754, 3766, 1024, 4754, 3766, 1041, 1011, 6236, 8325, 3967, 2592, 1024]\n",
            "  Decoded text (first 100 chars): [CLS] here ' s a professional resume for patrick williams : patrick williams e - commerce specialist contact information : * phone : ( 123 ) 456 - 7890 * email : [ patrick. williams @ email. com ] ( mailto : patrick. williams...\n",
            "  Label: 0 (Rejected)\n"
          ]
        }
      ],
      "source": [
        "# Inspect tokenization example\n",
        "example = tokenized_train[0]\n",
        "\n",
        "print(\"Tokenization Example:\")\n",
        "print(f\"  Input IDs length: {len(example['input_ids'])}\")\n",
        "print(f\"  First 20 tokens: {example['input_ids'][:20]}\")\n",
        "print(f\"  Decoded text (first 100 chars): {tokenizer.decode(example['input_ids'][:50])}...\")\n",
        "print(f\"  Label: {example['label']} ({'Accepted' if example['label'] == 1 else 'Rejected'})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Configuration:\n",
            "  Epochs: 3\n",
            "  Batch size (train): 8\n",
            "  Batch size (eval): 16\n",
            "  Learning rate: 2e-05\n",
            "  Mixed precision (FP16): True\n",
            "  Output directory: ..\\data\\models\\resume_classifier\n"
          ]
        }
      ],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(MODELS_DIR / 'resume_classifier'),\n",
        "    num_train_epochs=3,  # Start with 3 epochs\n",
        "    per_device_train_batch_size=8,  # Adjust based on GPU memory\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,  # Standard for BERT fine-tuning\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir=str(MODELS_DIR / 'logs'),\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,  # Keep only best 2 checkpoints\n",
        "    seed=42,\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
        ")\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size (train): {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Batch size (eval): {training_args.per_device_eval_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  Mixed precision (FP16): {training_args.fp16}\")\n",
        "print(f\"  Output directory: {training_args.output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Metrics function defined: accuracy, precision, recall, F1\n"
          ]
        }
      ],
      "source": [
        "# Define metrics computation\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy, precision, recall, and F1 score.\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary'\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "print(\"✓ Metrics function defined: accuracy, precision, recall, F1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Data collator initialized (dynamic padding)\n"
          ]
        }
      ],
      "source": [
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "print(\"✓ Data collator initialized (dynamic padding)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Initialize Trainer and Train Model\n",
        "\n",
        "**Note:** Training will take some time depending on hardware (GPU recommended).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Trainer initialized\n",
            "\n",
            "Training will start shortly...\n",
            "  Expected time: 10-30 minutes on GPU, 1-3 hours on CPU\n",
            "  Progress will be displayed below\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\reza\\AppData\\Local\\Temp\\ipykernel_10084\\692919354.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"✓ Trainer initialized\")\n",
        "print(\"\\nTraining will start shortly...\")\n",
        "print(\"  Expected time: 10-30 minutes on GPU, 1-3 hours on CPU\")\n",
        "print(\"  Progress will be displayed below\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STARTING TRAINING\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='617' max='2778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 615/2778 00:43 < 02:33, 14.13 it/s, Epoch 0.66/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.619800</td>\n",
              "      <td>0.598863</td>\n",
              "      <td>0.581622</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.271186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [58/58 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSTARTING TRAINING\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTRAINING COMPLETED!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2679\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2674\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2683\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "print(\"=\"*80)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTraining metrics:\")\n",
        "print(f\"  Training loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"  Training runtime: {train_result.metrics['train_runtime']:.2f} seconds\")\n",
        "print(f\"  Training samples/second: {train_result.metrics['train_samples_per_second']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n",
            "\n",
            "Validation Results:\n",
            "============================================================\n",
            "  Accuracy:  0.5816\n",
            "  Precision: 1.0000\n",
            "  Recall:    0.1569\n",
            "  F1 Score:  0.2712\n",
            "  Loss:      0.5989\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "print(\"Evaluating on validation set...\")\n",
        "val_metrics = trainer.evaluate(eval_dataset=tokenized_val)\n",
        "\n",
        "print(\"\\nValidation Results:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Accuracy:  {val_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"  Precision: {val_metrics['eval_precision']:.4f}\")\n",
        "print(f\"  Recall:    {val_metrics['eval_recall']:.4f}\")\n",
        "print(f\"  F1 Score:  {val_metrics['eval_f1']:.4f}\")\n",
        "print(f\"  Loss:      {val_metrics['eval_loss']:.4f}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results (Final Performance):\n",
            "============================================================\n",
            "  Accuracy:  0.6022\n",
            "  Precision: 0.5891\n",
            "  Recall:    0.6601\n",
            "  F1 Score:  0.6226\n",
            "  Loss:      0.5980\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on test set (final evaluation)\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_metrics = trainer.evaluate(eval_dataset=tokenized_test)\n",
        "\n",
        "print(\"\\nTest Results (Final Performance):\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Accuracy:  {test_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"  Precision: {test_metrics['eval_precision']:.4f}\")\n",
        "print(f\"  Recall:    {test_metrics['eval_recall']:.4f}\")\n",
        "print(f\"  F1 Score:  {test_metrics['eval_f1']:.4f}\")\n",
        "print(f\"  Loss:      {test_metrics['eval_loss']:.4f}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Generate Predictions and Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions generated\n",
            "  Total predictions: 926\n",
            "  Predicted Accepted: 54\n",
            "  Predicted Rejected: 872\n"
          ]
        }
      ],
      "source": [
        "# Get predictions on test set\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "pred_labels = np.argmax(predictions.predictions, axis=-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "print(\"Predictions generated\")\n",
        "print(f\"  Total predictions: {len(pred_labels)}\")\n",
        "print(f\"  Predicted Accepted: {(pred_labels == 1).sum()}\")\n",
        "print(f\"  Predicted Rejected: {(pred_labels == 0).sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix Breakdown:\n",
            "  True Negatives (Correctly predicted Rejected): 466\n",
            "  False Positives (Incorrectly predicted Accepted): 0\n",
            "  False Negatives (Incorrectly predicted Rejected): 406\n",
            "  True Positives (Correctly predicted Accepted): 54\n"
          ]
        }
      ],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Rejected', 'Accepted'],\n",
        "            yticklabels=['Rejected', 'Accepted'])\n",
        "plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nConfusion Matrix Breakdown:\")\n",
        "print(f\"  True Negatives (Correctly predicted Rejected): {cm[0,0]}\")\n",
        "print(f\"  False Positives (Incorrectly predicted Accepted): {cm[0,1]}\")\n",
        "print(f\"  False Negatives (Incorrectly predicted Rejected): {cm[1,0]}\")\n",
        "print(f\"  True Positives (Correctly predicted Accepted): {cm[1,1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Analyze Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Confidence Analysis:\n",
            "============================================================\n",
            "  Mean confidence: 0.5978\n",
            "  Median confidence: 0.5519\n",
            "  Min confidence: 0.5413\n",
            "  Max confidence: 0.9974\n",
            "\n",
            "  High confidence (>0.9): 97 (10.5%)\n",
            "  Low confidence (<0.6): 828 (89.4%)\n"
          ]
        }
      ],
      "source": [
        "# Get prediction probabilities\n",
        "pred_probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=-1)\n",
        "confidence_scores = pred_probs.max(dim=-1).values.numpy()\n",
        "\n",
        "print(\"Prediction Confidence Analysis:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Mean confidence: {confidence_scores.mean():.4f}\")\n",
        "print(f\"  Median confidence: {np.median(confidence_scores):.4f}\")\n",
        "print(f\"  Min confidence: {confidence_scores.min():.4f}\")\n",
        "print(f\"  Max confidence: {confidence_scores.max():.4f}\")\n",
        "\n",
        "# High confidence vs low confidence predictions\n",
        "high_conf_threshold = 0.9\n",
        "low_conf_threshold = 0.6\n",
        "\n",
        "high_conf = (confidence_scores > high_conf_threshold).sum()\n",
        "low_conf = (confidence_scores < low_conf_threshold).sum()\n",
        "\n",
        "print(f\"\\n  High confidence (>{high_conf_threshold}): {high_conf} ({high_conf/len(confidence_scores)*100:.1f}%)\")\n",
        "print(f\"  Low confidence (<{low_conf_threshold}): {low_conf} ({low_conf/len(confidence_scores)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Error Analysis:\n",
            "  Correct predictions: 613 (60.2%)\n",
            "  False positives: 233\n",
            "  False negatives: 172\n",
            "\n",
            "  Example False Positive (wrongly accepted):\n",
            "    Resume preview: Here's a professional resume for Herbert Campos, a UI Engineer candidate:\n",
            "\n",
            "Herbert Campos\n",
            "UI Engineer\n",
            "\n",
            "Contact Information:\n",
            "\n",
            "* Email: [herbert.campos@...\n",
            "    Confidence: 0.533\n",
            "\n",
            "  Example False Negative (wrongly rejected):\n",
            "    Resume preview: Here's a professional resume for Matthew Sexton:\n",
            "\n",
            "Matthew Sexton\n",
            "Cloud Engineer\n",
            "\n",
            "Contact Information:\n",
            "\n",
            "* Email: [matthew.sexton@email.com](mailto:matt...\n",
            "    Confidence: 0.523\n"
          ]
        }
      ],
      "source": [
        "# Analyze mistakes\n",
        "mistakes_df = test_df.copy().reset_index(drop=True)\n",
        "mistakes_df['predicted'] = pred_labels\n",
        "mistakes_df['correct'] = (mistakes_df['label'] == mistakes_df['predicted'])\n",
        "mistakes_df['confidence'] = confidence_scores\n",
        "\n",
        "# False positives (predicted Accepted but actually Rejected)\n",
        "false_positives = mistakes_df[(mistakes_df['label'] == 0) & (mistakes_df['predicted'] == 1)]\n",
        "# False negatives (predicted Rejected but actually Accepted)\n",
        "false_negatives = mistakes_df[(mistakes_df['label'] == 1) & (mistakes_df['predicted'] == 0)]\n",
        "\n",
        "print(f\"\\nError Analysis:\")\n",
        "print(f\"  Correct predictions: {mistakes_df['correct'].sum()} ({mistakes_df['correct'].sum()/len(mistakes_df)*100:.1f}%)\")\n",
        "print(f\"  False positives: {len(false_positives)}\")\n",
        "print(f\"  False negatives: {len(false_negatives)}\")\n",
        "\n",
        "if len(false_positives) > 0:\n",
        "    print(f\"\\n  Example False Positive (wrongly accepted):\")\n",
        "    fp_example = false_positives.iloc[0]\n",
        "    print(f\"    Resume preview: {fp_example['Resume'][:150]}...\")\n",
        "    print(f\"    Confidence: {fp_example['confidence']:.3f}\")\n",
        "\n",
        "if len(false_negatives) > 0:\n",
        "    print(f\"\\n  Example False Negative (wrongly rejected):\")\n",
        "    fn_example = false_negatives.iloc[0]\n",
        "    print(f\"    Resume preview: {fn_example['Resume'][:150]}...\")\n",
        "    print(f\"    Confidence: {fn_example['confidence']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Save Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to: ..\\data\\models\\resume_classifier_final\n",
            "✓ Model saved successfully\n",
            "✓ Location: c:\\Users\\reza\\Desktop\\prj\\resume-analyzer\\notebooks\\..\\data\\models\\resume_classifier_final\n",
            "✓ Model configuration saved: ..\\data\\models\\resume_classifier_final\\model_info.json\n"
          ]
        }
      ],
      "source": [
        "# Save the final model and tokenizer\n",
        "final_model_path = MODELS_DIR / 'resume_classifier_final'\n",
        "final_model_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Saving model to: {final_model_path}\")\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(str(final_model_path))\n",
        "tokenizer.save_pretrained(str(final_model_path))\n",
        "\n",
        "print(\"✓ Model saved successfully\")\n",
        "print(f\"✓ Location: {final_model_path.absolute()}\")\n",
        "\n",
        "# Save model configuration\n",
        "model_config = {\n",
        "    'model_name': model_name,\n",
        "    'num_labels': 2,\n",
        "    'max_length': 512,\n",
        "    'label_map': label_map,\n",
        "    'training_samples': len(train_df),\n",
        "    'validation_samples': len(val_df),\n",
        "    'test_samples': len(test_df),\n",
        "    'test_metrics': {\n",
        "        'accuracy': float(test_metrics['eval_accuracy']),\n",
        "        'precision': float(test_metrics['eval_precision']),\n",
        "        'recall': float(test_metrics['eval_recall']),\n",
        "        'f1': float(test_metrics['eval_f1'])\n",
        "    },\n",
        "    'training_config': {\n",
        "        'epochs': training_args.num_train_epochs,\n",
        "        'batch_size': training_args.per_device_train_batch_size,\n",
        "        'learning_rate': training_args.learning_rate\n",
        "    }\n",
        "}\n",
        "\n",
        "config_path = final_model_path / 'model_info.json'\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(model_config, f, indent=2)\n",
        "\n",
        "print(f\"✓ Model configuration saved: {config_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Test Model Inference\n",
        "\n",
        "Test the saved model with new examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Model Inference\n",
            "================================================================================\n",
            "\n",
            "Test Resume #1:\n",
            "------------------------------------------------------------\n",
            "Jane Smith\n",
            "    Senior Software Engineer\n",
            "\n",
            "    EXPERIENCE\n",
            "    - 8 years of Python development...\n",
            "\n",
            "Prediction: Rejected\n",
            "Confidence: 62.20%\n",
            "  Probability Rejected: 62.20%\n",
            "  Probability Accepted: 37.80%\n",
            "============================================================\n",
            "\n",
            "Test Resume #2:\n",
            "------------------------------------------------------------\n",
            "John Doe\n",
            "\n",
            "    Experience: worked with computers\n",
            "    Education: high school\n",
            "    Skills: Microsof...\n",
            "\n",
            "Prediction: Rejected\n",
            "Confidence: 50.17%\n",
            "  Probability Rejected: 50.17%\n",
            "  Probability Accepted: 49.83%\n",
            "============================================================\n",
            "\n",
            "✓ Model inference working correctly\n"
          ]
        }
      ],
      "source": [
        "# Define inference function\n",
        "def predict_resume(resume_text: str, model, tokenizer, device) -> dict:\n",
        "    \"\"\"\n",
        "    Predict if a resume will be accepted or rejected.\n",
        "    \n",
        "    Args:\n",
        "        resume_text: Resume text\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        device: Device to run inference on\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with prediction and confidence\n",
        "    \"\"\"\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        resume_text,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    \n",
        "    # Move to device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Get prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        prediction = torch.argmax(probs, dim=-1).item()\n",
        "        confidence = probs[0, prediction].item()\n",
        "    \n",
        "    return {\n",
        "        'prediction': prediction,\n",
        "        'decision': 'Accepted' if prediction == 1 else 'Rejected',\n",
        "        'confidence': confidence,\n",
        "        'prob_rejected': probs[0, 0].item(),\n",
        "        'prob_accepted': probs[0, 1].item()\n",
        "    }\n",
        "\n",
        "\n",
        "# Test with sample resumes\n",
        "test_resumes = [\n",
        "    \"\"\"\n",
        "    Jane Smith\n",
        "    Senior Software Engineer\n",
        "    \n",
        "    EXPERIENCE\n",
        "    - 8 years of Python development\n",
        "    - Led teams of 10+ engineers\n",
        "    - Expertise in AWS, Docker, Kubernetes\n",
        "    - Published 5 technical papers\n",
        "    \n",
        "    EDUCATION\n",
        "    PhD in Computer Science, MIT\n",
        "    MS in Data Science, Stanford\n",
        "    \n",
        "    SKILLS\n",
        "    Python, Java, TensorFlow, PyTorch, React\n",
        "    \"\"\",\n",
        "    \n",
        "    \"\"\"\n",
        "    John Doe\n",
        "    \n",
        "    Experience: worked with computers\n",
        "    Education: high school\n",
        "    Skills: Microsoft Word\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "print(\"Testing Model Inference\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, resume in enumerate(test_resumes, 1):\n",
        "    print(f\"\\nTest Resume #{i}:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(resume[:100].strip() + \"...\")\n",
        "    \n",
        "    result = predict_resume(resume, model, tokenizer, device)\n",
        "    \n",
        "    print(f\"\\nPrediction: {result['decision']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.2%}\")\n",
        "    print(f\"  Probability Rejected: {result['prob_rejected']:.2%}\")\n",
        "    print(f\"  Probability Accepted: {result['prob_accepted']:.2%}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n✓ Model inference working correctly\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Production Code\n",
        "\n",
        "The following class is ready for extraction into production modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Production class defined:\n",
            "  - ResumeClassifier class\n",
            "\n",
            "Methods:\n",
            "  - predict(resume_text)\n",
            "  - batch_predict(resume_texts)\n",
            "\n",
            "This class is ready to be extracted to models/resume_classifier.py\n"
          ]
        }
      ],
      "source": [
        "# PRODUCTION CODE\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class ResumeClassifier:\n",
        "    \"\"\"\n",
        "    Fine-tuned BERT/DistilBERT model for resume classification.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path: str):\n",
        "        \"\"\"\n",
        "        Initialize the classifier with a trained model.\n",
        "        \n",
        "        Args:\n",
        "            model_path: Path to saved model directory\n",
        "        \"\"\"\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "    \n",
        "    def predict(self, resume_text: str) -> dict:\n",
        "        \"\"\"\n",
        "        Predict if a resume will be accepted or rejected.\n",
        "        \n",
        "        Args:\n",
        "            resume_text: Resume text to classify\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary with prediction, confidence, and probabilities\n",
        "        \"\"\"\n",
        "        # Tokenize\n",
        "        inputs = self.tokenizer(\n",
        "            resume_text,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        # Move to device\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "        \n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            prediction = torch.argmax(probs, dim=-1).item()\n",
        "            confidence = probs[0, prediction].item()\n",
        "        \n",
        "        return {\n",
        "            'prediction': prediction,\n",
        "            'decision': 'Accepted' if prediction == 1 else 'Rejected',\n",
        "            'confidence': confidence,\n",
        "            'prob_rejected': probs[0, 0].item(),\n",
        "            'prob_accepted': probs[0, 1].item()\n",
        "        }\n",
        "    \n",
        "    def batch_predict(self, resume_texts: list) -> list:\n",
        "        \"\"\"\n",
        "        Predict classifications for multiple resumes.\n",
        "        \n",
        "        Args:\n",
        "            resume_texts: List of resume texts\n",
        "        \n",
        "        Returns:\n",
        "            List of prediction dictionaries\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        for resume_text in resume_texts:\n",
        "            result = self.predict(resume_text)\n",
        "            results.append(result)\n",
        "        return results\n",
        "\n",
        "\n",
        "print(\"✓ Production class defined:\")\n",
        "print(\"  - ResumeClassifier class\")\n",
        "print(\"\\nMethods:\")\n",
        "print(\"  - predict(resume_text)\")\n",
        "print(\"  - batch_predict(resume_texts)\")\n",
        "print(\"\\nThis class is ready to be extracted to models/resume_classifier.py\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing Production Class:\n",
            "============================================================\n",
            "\n",
            "Test Resume:\n",
            "\n",
            "Senior Data Scientist with 7 years of experience.\n",
            "Expert in Python, TensorFlow, PyTorch, and AWS.\n",
            "P...\n",
            "\n",
            "Prediction: Rejected\n",
            "Confidence: 63.81%\n",
            "\n",
            "✓ Production class tested successfully\n"
          ]
        }
      ],
      "source": [
        "# Test the production class\n",
        "print(\"\\nTesting Production Class:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize classifier with saved model\n",
        "classifier = ResumeClassifier(str(final_model_path))\n",
        "\n",
        "# Test prediction\n",
        "test_resume = \"\"\"\n",
        "Senior Data Scientist with 7 years of experience.\n",
        "Expert in Python, TensorFlow, PyTorch, and AWS.\n",
        "PhD in Machine Learning from Stanford University.\n",
        "Published 10+ research papers in top conferences.\n",
        "\"\"\"\n",
        "\n",
        "result = classifier.predict(test_resume)\n",
        "\n",
        "print(f\"\\nTest Resume:\")\n",
        "print(test_resume[:100] + \"...\")\n",
        "print(f\"\\nPrediction: {result['decision']}\")\n",
        "print(f\"Confidence: {result['confidence']:.2%}\")\n",
        "\n",
        "print(\"\\n✓ Production class tested successfully\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
