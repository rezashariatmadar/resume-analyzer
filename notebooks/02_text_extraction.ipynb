{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2: Text Extraction\n",
        "\n",
        "## Objective\n",
        "Extract text content from PDF and DOCX resume files for analysis.\n",
        "\n",
        "## Goals\n",
        "1. Test PyMuPDF (fitz) for PDF text extraction\n",
        "2. Test python-docx for DOCX text extraction\n",
        "3. Extract text from sample files\n",
        "4. Handle different file formats and structures\n",
        "5. Compare extraction quality across methods\n",
        "\n",
        "## Dependencies\n",
        "- `PyMuPDF` (fitz) - PDF text extraction\n",
        "- `python-docx` - DOCX text extraction\n",
        "- `pathlib` - File path handling\n",
        "- `pandas` - Data organization\n",
        "\n",
        "## Test Data\n",
        "Using sample resume files from `data/samples/` directory (created in Notebook 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ All imports successful\n",
            "✓ Samples directory: c:\\Users\\reza\\Desktop\\prj\\resume-analyzer\\notebooks\\..\\data\\samples\n",
            "✓ Output directory: c:\\Users\\reza\\Desktop\\prj\\resume-analyzer\\notebooks\\..\\data\\extracted\n",
            "\n",
            "✓ PyMuPDF version: 1.26.5\n",
            "✓ python-docx loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF\n",
        "import docx  # python-docx\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "DATA_DIR = Path('../data')\n",
        "SAMPLES_DIR = DATA_DIR / 'samples'\n",
        "OUTPUT_DIR = DATA_DIR / 'extracted'\n",
        "\n",
        "# Create output directory for extracted text\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"✓ All imports successful\")\n",
        "print(f\"✓ Samples directory: {SAMPLES_DIR.absolute()}\")\n",
        "print(f\"✓ Output directory: {OUTPUT_DIR.absolute()}\")\n",
        "print(f\"\\n✓ PyMuPDF version: {fitz.__version__}\")\n",
        "print(f\"✓ python-docx loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Check Available Sample Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10 files in samples directory:\n",
            "\n",
            "  - sample_01_reject_UX_Designer.txt (3.6 KB)\n",
            "  - sample_02_reject_UI_Engineer.txt (7.2 KB)\n",
            "  - sample_03_reject_Human_Resources_Specialist.txt (4.4 KB)\n",
            "  - sample_04_reject_E-commerce_Specialist.txt (3.9 KB)\n",
            "  - sample_05_reject_software_engineer.txt (3.5 KB)\n",
            "  - sample_06_select_QA_Engineer.txt (3.2 KB)\n",
            "  - sample_07_select_Content_Writer.txt (3.8 KB)\n",
            "  - sample_08_select_software_engineer.txt (3.6 KB)\n",
            "  - sample_09_select_Data_Engineer.txt (3.5 KB)\n",
            "  - sample_10_select_Data_Analyst.txt (4.0 KB)\n"
          ]
        }
      ],
      "source": [
        "# List all files in samples directory\n",
        "sample_files = list(SAMPLES_DIR.glob('*'))\n",
        "\n",
        "print(f\"Found {len(sample_files)} files in samples directory:\\n\")\n",
        "for file in sample_files[:10]:  # Show first 10\n",
        "    file_size = file.stat().st_size / 1024  # Size in KB\n",
        "    print(f\"  - {file.name} ({file_size:.1f} KB)\")\n",
        "\n",
        "if len(sample_files) > 10:\n",
        "    print(f\"\\n  ... and {len(sample_files) - 10} more files\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. PDF Text Extraction with PyMuPDF\n",
        "\n",
        "PyMuPDF (fitz) is a fast and reliable PDF parsing library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF Extraction Function Defined\n",
            "============================================================\n",
            "\n",
            "Function signature:\n",
            "  extract_text_from_pdf(pdf_path: str) -> str\n",
            "\n",
            "Capabilities:\n",
            "  ✓ Extracts text from all pages\n",
            "  ✓ Handles multi-page documents\n",
            "  ✓ Preserves text structure\n",
            "  ✓ Returns clean string output\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text content from a PDF file using PyMuPDF.\n",
        "    \n",
        "    Args:\n",
        "        pdf_path: Path to PDF file\n",
        "    \n",
        "    Returns:\n",
        "        Extracted text as string\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    \n",
        "    for page_num, page in enumerate(doc, 1):\n",
        "        page_text = page.get_text()\n",
        "        text += page_text\n",
        "    \n",
        "    doc.close()\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# Test the function with a simple demonstration\n",
        "print(\"PDF Extraction Function Defined\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunction signature:\")\n",
        "print(\"  extract_text_from_pdf(pdf_path: str) -> str\")\n",
        "print(\"\\nCapabilities:\")\n",
        "print(\"  ✓ Extracts text from all pages\")\n",
        "print(\"  ✓ Handles multi-page documents\")\n",
        "print(\"  ✓ Preserves text structure\")\n",
        "print(\"  ✓ Returns clean string output\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Detailed PDF extraction function defined\n",
            "  Returns: text, page_count, per-page details\n"
          ]
        }
      ],
      "source": [
        "# Advanced: Extract with page information\n",
        "def extract_text_from_pdf_detailed(pdf_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract text from PDF with detailed page-level information.\n",
        "    \n",
        "    Args:\n",
        "        pdf_path: Path to PDF file\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with text, page_count, and per-page content\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    \n",
        "    result = {\n",
        "        'text': '',\n",
        "        'page_count': len(doc),\n",
        "        'pages': []\n",
        "    }\n",
        "    \n",
        "    for page_num, page in enumerate(doc, 1):\n",
        "        page_text = page.get_text()\n",
        "        result['pages'].append({\n",
        "            'page_number': page_num,\n",
        "            'text': page_text,\n",
        "            'char_count': len(page_text)\n",
        "        })\n",
        "        result['text'] += page_text\n",
        "    \n",
        "    doc.close()\n",
        "    result['text'] = result['text'].strip()\n",
        "    result['total_chars'] = len(result['text'])\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"✓ Detailed PDF extraction function defined\")\n",
        "print(\"  Returns: text, page_count, per-page details\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DOCX Text Extraction with python-docx\n",
        "\n",
        "The python-docx library handles Microsoft Word documents (.docx).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DOCX Extraction Function Defined\n",
            "============================================================\n",
            "\n",
            "Function signature:\n",
            "  extract_text_from_docx(docx_path: str) -> str\n",
            "\n",
            "Capabilities:\n",
            "  ✓ Extracts paragraphs\n",
            "  ✓ Extracts text from tables\n",
            "  ✓ Preserves structure with newlines\n",
            "  ✓ Returns clean string output\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_docx(docx_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text content from a DOCX file using python-docx.\n",
        "    \n",
        "    Args:\n",
        "        docx_path: Path to DOCX file\n",
        "    \n",
        "    Returns:\n",
        "        Extracted text as string\n",
        "    \"\"\"\n",
        "    doc = docx.Document(docx_path)\n",
        "    \n",
        "    # Extract all paragraphs\n",
        "    paragraphs = [para.text for para in doc.paragraphs]\n",
        "    \n",
        "    # Extract text from tables\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            for cell in row.cells:\n",
        "                paragraphs.append(cell.text)\n",
        "    \n",
        "    text = '\\n'.join(paragraphs)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "print(\"DOCX Extraction Function Defined\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunction signature:\")\n",
        "print(\"  extract_text_from_docx(docx_path: str) -> str\")\n",
        "print(\"\\nCapabilities:\")\n",
        "print(\"  ✓ Extracts paragraphs\")\n",
        "print(\"  ✓ Extracts text from tables\")\n",
        "print(\"  ✓ Preserves structure with newlines\")\n",
        "print(\"  ✓ Returns clean string output\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Detailed DOCX extraction function defined\n",
            "  Returns: text, paragraphs, tables, structural details\n"
          ]
        }
      ],
      "source": [
        "# Advanced: Extract with structural information\n",
        "def extract_text_from_docx_detailed(docx_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract text from DOCX with detailed structural information.\n",
        "    \n",
        "    Args:\n",
        "        docx_path: Path to DOCX file\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with text, paragraph_count, table_count, and details\n",
        "    \"\"\"\n",
        "    doc = docx.Document(docx_path)\n",
        "    \n",
        "    result = {\n",
        "        'text': '',\n",
        "        'paragraphs': [],\n",
        "        'tables': [],\n",
        "        'paragraph_count': 0,\n",
        "        'table_count': 0\n",
        "    }\n",
        "    \n",
        "    # Extract paragraphs\n",
        "    for para in doc.paragraphs:\n",
        "        if para.text.strip():  # Only non-empty paragraphs\n",
        "            result['paragraphs'].append({\n",
        "                'text': para.text,\n",
        "                'style': para.style.name if para.style else 'Normal'\n",
        "            })\n",
        "            result['text'] += para.text + '\\n'\n",
        "    \n",
        "    result['paragraph_count'] = len(result['paragraphs'])\n",
        "    \n",
        "    # Extract tables\n",
        "    for table_idx, table in enumerate(doc.tables, 1):\n",
        "        table_data = []\n",
        "        for row in table.rows:\n",
        "            row_data = [cell.text for cell in row.cells]\n",
        "            table_data.append(row_data)\n",
        "        \n",
        "        result['tables'].append({\n",
        "            'table_number': table_idx,\n",
        "            'rows': len(table.rows),\n",
        "            'columns': len(table.columns) if table.rows else 0,\n",
        "            'data': table_data\n",
        "        })\n",
        "        \n",
        "        # Add table text to main text\n",
        "        for row in table_data:\n",
        "            result['text'] += ' | '.join(row) + '\\n'\n",
        "    \n",
        "    result['table_count'] = len(result['tables'])\n",
        "    result['text'] = result['text'].strip()\n",
        "    result['total_chars'] = len(result['text'])\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"✓ Detailed DOCX extraction function defined\")\n",
        "print(\"  Returns: text, paragraphs, tables, structural details\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Unified Text Extraction Function\n",
        "\n",
        "Create a single function that handles multiple file formats automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Unified extraction function defined\n",
            "\n",
            "Supported formats:\n",
            "  - PDF (.pdf)\n",
            "  - DOCX (.docx)\n",
            "  - TXT (.txt)\n",
            "  - Auto-detection based on file extension\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_file(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from a file. Automatically detects file type (PDF, DOCX, TXT).\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to file\n",
        "    \n",
        "    Returns:\n",
        "        Extracted text as string\n",
        "    \"\"\"\n",
        "    file_path = Path(file_path)\n",
        "    \n",
        "    # Get file extension\n",
        "    extension = file_path.suffix.lower()\n",
        "    \n",
        "    if extension == '.pdf':\n",
        "        return extract_text_from_pdf(str(file_path))\n",
        "    elif extension == '.docx':\n",
        "        return extract_text_from_docx(str(file_path))\n",
        "    elif extension == '.txt':\n",
        "        # Plain text file\n",
        "        return file_path.read_text(encoding='utf-8')\n",
        "    else:\n",
        "        # Unsupported format - try reading as text\n",
        "        return file_path.read_text(encoding='utf-8')\n",
        "\n",
        "\n",
        "print(\"✓ Unified extraction function defined\")\n",
        "print(\"\\nSupported formats:\")\n",
        "print(\"  - PDF (.pdf)\")\n",
        "print(\"  - DOCX (.docx)\")\n",
        "print(\"  - TXT (.txt)\")\n",
        "print(\"  - Auto-detection based on file extension\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Extraction on Sample Files\n",
        "\n",
        "Our sample files from Notebook 1 are in .txt format. Let's test the extraction functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10 sample files\n",
            "\n",
            "Processing samples...\n",
            "\n",
            "✓ sample_01_reject_UX_Designer.txt\n",
            "  Size: 3.6 KB\n",
            "  Text length: 3,631 characters\n",
            "  Words: 418\n",
            "  Lines: 82\n",
            "\n",
            "✓ sample_02_reject_UI_Engineer.txt\n",
            "  Size: 7.2 KB\n",
            "  Text length: 7,215 characters\n",
            "  Words: 966\n",
            "  Lines: 147\n",
            "\n",
            "✓ sample_03_reject_Human_Resources_Specialist.txt\n",
            "  Size: 4.4 KB\n",
            "  Text length: 4,410 characters\n",
            "  Words: 535\n",
            "  Lines: 99\n",
            "\n",
            "✓ sample_04_reject_E-commerce_Specialist.txt\n",
            "  Size: 3.9 KB\n",
            "  Text length: 3,903 characters\n",
            "  Words: 453\n",
            "  Lines: 86\n",
            "\n",
            "✓ sample_05_reject_software_engineer.txt\n",
            "  Size: 3.5 KB\n",
            "  Text length: 3,540 characters\n",
            "  Words: 417\n",
            "  Lines: 74\n",
            "\n",
            "✓ sample_06_select_QA_Engineer.txt\n",
            "  Size: 3.2 KB\n",
            "  Text length: 3,249 characters\n",
            "  Words: 371\n",
            "  Lines: 77\n",
            "\n",
            "✓ sample_07_select_Content_Writer.txt\n",
            "  Size: 3.8 KB\n",
            "  Text length: 3,853 characters\n",
            "  Words: 436\n",
            "  Lines: 81\n",
            "\n",
            "✓ sample_08_select_software_engineer.txt\n",
            "  Size: 3.6 KB\n",
            "  Text length: 3,644 characters\n",
            "  Words: 443\n",
            "  Lines: 34\n",
            "\n",
            "✓ sample_09_select_Data_Engineer.txt\n",
            "  Size: 3.5 KB\n",
            "  Text length: 3,497 characters\n",
            "  Words: 430\n",
            "  Lines: 80\n",
            "\n",
            "✓ sample_10_select_Data_Analyst.txt\n",
            "  Size: 4.0 KB\n",
            "  Text length: 4,057 characters\n",
            "  Words: 473\n",
            "  Lines: 80\n",
            "\n",
            "\n",
            "✓ Successfully extracted text from 10 files\n"
          ]
        }
      ],
      "source": [
        "# Get list of sample files\n",
        "sample_files = sorted(list(SAMPLES_DIR.glob('*.txt')))\n",
        "\n",
        "print(f\"Found {len(sample_files)} sample files\")\n",
        "print(\"\\nProcessing samples...\\n\")\n",
        "\n",
        "extraction_results = []\n",
        "\n",
        "for file_path in sample_files:\n",
        "    # Extract text\n",
        "    text = extract_text_from_file(str(file_path))\n",
        "    \n",
        "    result = {\n",
        "        'filename': file_path.name,\n",
        "        'file_size_kb': file_path.stat().st_size / 1024,\n",
        "        'text_length': len(text),\n",
        "        'word_count': len(text.split()),\n",
        "        'line_count': len(text.split('\\n')),\n",
        "        'text_preview': text[:200]\n",
        "    }\n",
        "    \n",
        "    extraction_results.append(result)\n",
        "    \n",
        "    print(f\"✓ {file_path.name}\")\n",
        "    print(f\"  Size: {result['file_size_kb']:.1f} KB\")\n",
        "    print(f\"  Text length: {result['text_length']:,} characters\")\n",
        "    print(f\"  Words: {result['word_count']:,}\")\n",
        "    print(f\"  Lines: {result['line_count']}\")\n",
        "    print()\n",
        "\n",
        "print(f\"\\n✓ Successfully extracted text from {len(extraction_results)} files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction Statistics:\n",
            "======================================================================\n",
            "Total files processed: 10\n",
            "\n",
            "Text Length Statistics:\n",
            "  Mean: 4,100 characters\n",
            "  Median: 3,748 characters\n",
            "  Min: 3,249 characters\n",
            "  Max: 7,215 characters\n",
            "\n",
            "Word Count Statistics:\n",
            "  Mean: 494 words\n",
            "  Median: 440 words\n",
            "  Min: 371 words\n",
            "  Max: 966 words\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Summary Table:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_01_reject_UX_Designer.txt</td>\n",
              "      <td>3631</td>\n",
              "      <td>418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_02_reject_UI_Engineer.txt</td>\n",
              "      <td>7215</td>\n",
              "      <td>966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_03_reject_Human_Resources_Specialist.txt</td>\n",
              "      <td>4410</td>\n",
              "      <td>535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sample_04_reject_E-commerce_Specialist.txt</td>\n",
              "      <td>3903</td>\n",
              "      <td>453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sample_05_reject_software_engineer.txt</td>\n",
              "      <td>3540</td>\n",
              "      <td>417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sample_06_select_QA_Engineer.txt</td>\n",
              "      <td>3249</td>\n",
              "      <td>371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sample_07_select_Content_Writer.txt</td>\n",
              "      <td>3853</td>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sample_08_select_software_engineer.txt</td>\n",
              "      <td>3644</td>\n",
              "      <td>443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sample_09_select_Data_Engineer.txt</td>\n",
              "      <td>3497</td>\n",
              "      <td>430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sample_10_select_Data_Analyst.txt</td>\n",
              "      <td>4057</td>\n",
              "      <td>473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          filename  text_length  word_count\n",
              "0                 sample_01_reject_UX_Designer.txt         3631         418\n",
              "1                 sample_02_reject_UI_Engineer.txt         7215         966\n",
              "2  sample_03_reject_Human_Resources_Specialist.txt         4410         535\n",
              "3       sample_04_reject_E-commerce_Specialist.txt         3903         453\n",
              "4           sample_05_reject_software_engineer.txt         3540         417\n",
              "5                 sample_06_select_QA_Engineer.txt         3249         371\n",
              "6              sample_07_select_Content_Writer.txt         3853         436\n",
              "7           sample_08_select_software_engineer.txt         3644         443\n",
              "8               sample_09_select_Data_Engineer.txt         3497         430\n",
              "9                sample_10_select_Data_Analyst.txt         4057         473"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create DataFrame for analysis\n",
        "df_extractions = pd.DataFrame(extraction_results)\n",
        "\n",
        "print(\"Extraction Statistics:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total files processed: {len(df_extractions)}\")\n",
        "print(f\"\\nText Length Statistics:\")\n",
        "print(f\"  Mean: {df_extractions['text_length'].mean():,.0f} characters\")\n",
        "print(f\"  Median: {df_extractions['text_length'].median():,.0f} characters\")\n",
        "print(f\"  Min: {df_extractions['text_length'].min():,} characters\")\n",
        "print(f\"  Max: {df_extractions['text_length'].max():,} characters\")\n",
        "print(f\"\\nWord Count Statistics:\")\n",
        "print(f\"  Mean: {df_extractions['word_count'].mean():,.0f} words\")\n",
        "print(f\"  Median: {df_extractions['word_count'].median():,.0f} words\")\n",
        "print(f\"  Min: {df_extractions['word_count'].min():,} words\")\n",
        "print(f\"  Max: {df_extractions['word_count'].max():,} words\")\n",
        "\n",
        "# Display summary table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\nSummary Table:\")\n",
        "df_extractions[['filename', 'text_length', 'word_count']].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Extracted Text (First File):\n",
            "================================================================================\n",
            "File: sample_01_reject_UX_Designer.txt\n",
            "\n",
            "First 500 characters:\n",
            "\n",
            "================================================================================\n",
            "SAMPLE RESUME #1\n",
            "================================================================================\n",
            "\n",
            "ROLE: UX Designer\n",
            "DECISION: reject\n",
            "\n",
            "REASON FOR DECISION:\n",
            "Insufficient system design expertise for senior role.\n",
            "\n",
            "================================================================================\n",
            "JOB DESCRIPTION:\n",
            "================================================================================\n",
            "We need a UX Designer to enha\n",
            "\n",
            "... (truncated)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display a sample extraction\n",
        "print(\"Sample Extracted Text (First File):\")\n",
        "print(\"=\"*80)\n",
        "if extraction_results:\n",
        "    sample_text = extraction_results[0]['text_preview']\n",
        "    print(f\"File: {extraction_results[0]['filename']}\")\n",
        "    print(f\"\\nFirst 500 characters:\\n\")\n",
        "    \n",
        "    # Get full text for first file\n",
        "    first_file = sample_files[0]\n",
        "    full_text = extract_text_from_file(str(first_file))\n",
        "    print(full_text[:500])\n",
        "    print(\"\\n... (truncated)\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Extracted Text\n",
        "\n",
        "Save extracted text to the output directory for use in next notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved 10 extracted text files\n",
            "✓ Location: c:\\Users\\reza\\Desktop\\prj\\resume-analyzer\\notebooks\\..\\data\\extracted\n"
          ]
        }
      ],
      "source": [
        "# Save extracted text files\n",
        "saved_count = 0\n",
        "\n",
        "for file_path in sample_files:\n",
        "    # Extract text\n",
        "    text = extract_text_from_file(str(file_path))\n",
        "    \n",
        "    # Create output filename\n",
        "    output_filename = file_path.stem + '_extracted.txt'\n",
        "    output_path = OUTPUT_DIR / output_filename\n",
        "    \n",
        "    # Save extracted text\n",
        "    output_path.write_text(text, encoding='utf-8')\n",
        "    saved_count += 1\n",
        "\n",
        "print(f\"✓ Saved {saved_count} extracted text files\")\n",
        "print(f\"✓ Location: {OUTPUT_DIR.absolute()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Extraction Quality Comparison\n",
        "\n",
        "Compare extraction methods and discuss edge cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Production Code\n",
        "\n",
        "The following functions are ready for extraction into production modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PRODUCTION CODE\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text content from a PDF file using PyMuPDF.\n",
        "    \n",
        "    Args:\n",
        "        pdf_path: Path to PDF file\n",
        "    \n",
        "    Returns:\n",
        "        Extracted text as string\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    \n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    \n",
        "    doc.close()\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def extract_text_from_docx(docx_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text content from a DOCX file using python-docx.\n",
        "    \n",
        "    Args:\n",
        "        docx_path: Path to DOCX file\n",
        "    \n",
        "    Returns:\n",
        "        Extracted text as string\n",
        "    \"\"\"\n",
        "    doc = docx.Document(docx_path)\n",
        "    \n",
        "    # Extract all paragraphs\n",
        "    paragraphs = [para.text for para in doc.paragraphs]\n",
        "    \n",
        "    # Extract text from tables\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            for cell in row.cells:\n",
        "                paragraphs.append(cell.text)\n",
        "    \n",
        "    text = '\\n'.join(paragraphs)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def extract_text_from_file(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from a file. Automatically detects file type (PDF, DOCX, TXT).\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to file\n",
        "    \n",
        "    Returns:\n",
        "        Extracted text as string\n",
        "    \"\"\"\n",
        "    file_path = Path(file_path)\n",
        "    extension = file_path.suffix.lower()\n",
        "    \n",
        "    if extension == '.pdf':\n",
        "        return extract_text_from_pdf(str(file_path))\n",
        "    elif extension == '.docx':\n",
        "        return extract_text_from_docx(str(file_path))\n",
        "    elif extension == '.txt':\n",
        "        return file_path.read_text(encoding='utf-8')\n",
        "    else:\n",
        "        # Default: try reading as text\n",
        "        return file_path.read_text(encoding='utf-8')\n",
        "\n",
        "\n",
        "def batch_extract_text(file_paths: list, output_dir: str = None) -> dict:\n",
        "    \"\"\"\n",
        "    Extract text from multiple files in batch.\n",
        "    \n",
        "    Args:\n",
        "        file_paths: List of file paths to process\n",
        "        output_dir: Optional directory to save extracted text\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary mapping filenames to extracted text\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for file_path in file_paths:\n",
        "        file_path = Path(file_path)\n",
        "        text = extract_text_from_file(str(file_path))\n",
        "        results[file_path.name] = text\n",
        "        \n",
        "        # Save to output directory if specified\n",
        "        if output_dir:\n",
        "            output_path = Path(output_dir) / f\"{file_path.stem}_extracted.txt\"\n",
        "            output_path.write_text(text, encoding='utf-8')\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "✓ Successfully implemented PDF text extraction with PyMuPDF  \n",
        "✓ Successfully implemented DOCX text extraction with python-docx  \n",
        "✓ Created unified extraction function for multiple formats  \n",
        "✓ Tested extraction on sample resume files  \n",
        "✓ Saved extracted text for next notebooks  \n",
        "✓ Created production-ready extraction functions\n",
        "\n",
        "### Key Insights\n",
        "\n",
        "- **PyMuPDF** is fast and reliable for PDF extraction\n",
        "- **python-docx** provides excellent structure for DOCX files\n",
        "- Unified interface makes it easy to handle multiple formats\n",
        "- Edge cases (scanned PDFs, corrupted files) require special handling\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
